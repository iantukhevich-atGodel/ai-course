<h1>Diagnosing Root Causes</h1>
<ul>
	Once a prompt produces unsatisfactory results, the next step is to analyze why the failure occurred. This involves reviewing both the prompt and the output systematically. Consider the following questions:
	<li>
		Did the prompt clearly define the task and expected format?
	</li>
	<li>
		Was the context sufficient for the model to generate relevant outputs?
	</li>
	<li>
		Are there ambiguous terms or instructions that could confuse the model?
	</li>
	<li>
		Was the prompt overloaded with multiple, conflicting instructions?
	</li>
</ul>
<p>
	<b>Example:</b><br>
	A model generates a set of test cases but fails to include negative scenarios. On inspection, the prompt reads:
</p>
<pre>
	<code>
Generate test cases for a registration page. Include valid inputs.
	</code>
</pre>
<p>
	The root cause is immediately apparent: the prompt explicitly asks for “valid inputs” and omits mention of invalid or edge-case scenarios.
</p>
<p>
	<b>Guidance:</b>
	Diagnosing failures requires careful reading of both the input prompt and the output. Documenting observed inconsistencies helps identify patterns and recurring issues.
</p>

<footer>
	{Image placeholder: Diagram showing prompt review → error identification → root cause highlighted}
</footer>