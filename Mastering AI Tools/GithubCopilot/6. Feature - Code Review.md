<p>
	Copilot can 
	<a href='https://docs.github.com/en/copilot/concepts/code-review'>review pull requests</a>
	on GitHub.com, in IDEs, and on mobile, offering feedback and suggested changes you can apply with a click. Availability depends on plan and context, and there is a monthly premium‑request quota for deep reviews. In VS Code you can also request a review of uncommitted changes or a selected region, with different limits and behavior. Treat Copilot’s output as a first pass that you validate and refine. Keep a human in the loop for security, policy, and architecture concerns.
</p>

<p>
	Good prompts for review specify standards, risks, and priorities. For example: “Focus on concurrency issues and SQL injection risks; follow our <em>db-utils</em> pattern; suggest minimal diffs.” You can provide repository and organization custom instructions so Copilot reviews align with your rules automatically. Ask the reviewer to cite where it found each issue and to propose tests that prove the fix. This produces actionable and auditable feedback.
</p>

<p>
	Automatic reviews can be configured for new PRs at user, repo, or org scope. Each automatic review consumes from the author’s quota, and the system runs only once per PR unless you manually request another pass. This is helpful for consistent hygiene on routine changes while leaving complex work to human reviewers. Capture false positives in a follow‑up prompt to improve subsequent reviews. Over time, your instructions will encode your style guide. 
</p>

<p>
	In the IDE, start with a selection review to get fast feedback on a risky block. If useful, escalate to a full “review changes” pass that examines all uncommitted edits and respects your custom instructions. Ask for a summary with a severity table and exact code references. Require it to include a minimal reproducer for any non-trivial claim. This keeps feedback crisp and testable.
</p>

<p>
	Exercise: enable automatic reviews for a safe repository and track precision and recall versus human findings. Tweak instructions to reduce noise, then try a complex PR and compare depth of feedback. Ask Copilot to turn its review into failing tests you can run locally. Finish with a short debrief documenting gaps and improvements. This turns AI review into a measurable practice.
</p>

<pre><code class="language-mermaid">
	flowchart LR
	  PR[Pull Request] --> CR[Copilot Review]
	  CR --> SUGG[Suggested Changes]
	  SUGG --> DEV[Developer Applies/Rejects]
	  DEV --> TESTS[Run CI]
	  TESTS --> MERGE[Merge Decision]
</code></pre>